# 운영체제 면접 질문 & 답변

## 사용 방법
1. 질문을 먼저 읽고 스스로 답변해보세요
2. 답변을 확인하고 부족한 부분을 학습하세요
3. ⭐ 표시는 빈출 질문입니다

---

## Q1. 프로세스와 스레드의 차이점은 무엇인가요? ⭐⭐⭐

<details>
<summary>답변 보기</summary>

### 핵심 답변
프로세스는 **자원 할당의 단위**이고, 스레드는 **실행의 단위**입니다. 프로세스는 독립적인 메모리 공간을 가지며, 스레드는 같은 프로세스 내에서 Code, Data, Heap 영역을 공유하고 Stack만 독립적으로 가집니다.

### 상세 설명
- **프로세스**: 독립적인 메모리 공간 (Code, Data, Heap, Stack 모두 독립)
- **스레드**: 프로세스 내에서 Code, Data, Heap 공유, Stack만 독립

### 면접관이 주목하는 포인트
- 컨텍스트 스위칭 비용 차이 설명
- 메모리 공유로 인한 동기화 이슈 언급
- 실무 선택 기준 제시

### 꼬리 질문 대비
- "멀티 프로세스와 멀티 스레드 중 언제 무엇을 선택하나요?"
  → 안정성 필요: 멀티 프로세스, 성능 필요: 멀티 스레드
- "크롬 브라우저가 멀티 프로세스 방식을 사용하는 이유는?"
  → 탭 하나의 크래시가 전체에 영향을 주지 않도록 격리

### 관련 개념
- [프로세스와 스레드](./01-process-thread.md)

</details>

---

## Q2. 컨텍스트 스위칭이란 무엇이며, 성능에 어떤 영향을 미치나요? ⭐⭐

<details>
<summary>답변 보기</summary>

### 핵심 답변
컨텍스트 스위칭은 CPU가 현재 실행 중인 프로세스(스레드)의 상태를 저장하고, 다른 프로세스(스레드)의 상태를 복원하여 실행을 전환하는 과정입니다.

### 상세 설명

**저장되는 컨텍스트:**
- Program Counter (PC)
- CPU 레지스터
- 메모리 관리 정보
- I/O 상태 정보

**비용 차이:**
- 프로세스 스위칭: TLB 플러시, 캐시 미스 → 비용 높음
- 스레드 스위칭: 레지스터만 교체 → 비용 낮음

### 면접관이 주목하는 포인트
- TLB 플러시의 영향 설명
- 캐시 적중률 저하 언급
- 성능 최적화 방안 제시

### 꼬리 질문 대비
- "컨텍스트 스위칭 오버헤드를 줄이는 방법은?"
  → 스레드 풀 사용, 비동기 I/O, CPU 친화도 설정

### 관련 개념
- [컨텍스트 스위칭](./03-context-switching.md)

</details>

---

## Q3. 데드락(교착 상태)이란 무엇이며, 발생 조건 4가지를 설명해주세요. ⭐⭐⭐

<details>
<summary>답변 보기</summary>

### 핵심 답변
데드락은 두 개 이상의 프로세스(스레드)가 서로가 보유한 자원을 기다리며 무한 대기하는 상태입니다.

### 발생 조건 (4가지 모두 충족 시)
1. **상호 배제 (Mutual Exclusion)**: 자원은 한 번에 하나의 프로세스만 사용 가능
2. **점유 대기 (Hold and Wait)**: 자원을 보유한 채로 다른 자원을 기다림
3. **비선점 (No Preemption)**: 다른 프로세스의 자원을 강제로 빼앗을 수 없음
4. **순환 대기 (Circular Wait)**: 프로세스들이 순환 형태로 자원을 기다림

### 해결 방법
- **예방**: 4가지 조건 중 하나 제거
- **회피**: 은행원 알고리즘 (안전 상태 유지)
- **탐지/복구**: 주기적 탐지 후 프로세스 종료
- **무시**: 발생 확률 낮으면 무시 (시스템 재시작)

### 면접관이 주목하는 포인트
- 4가지 조건 정확히 암기
- 실무에서의 해결 경험
- 예방 vs 회피 vs 탐지 트레이드오프

### 꼬리 질문 대비
- "프로젝트에서 데드락을 경험한 적 있나요?"
- "순환 대기 조건을 깨는 방법은?"
  → 자원에 순서를 부여하고, 순서대로만 자원 요청

### 관련 개념
- [교착 상태와 경쟁 상태](./04-deadlock-race-condition.md)

</details>

---

## Q4. 경쟁 상태(Race Condition)란 무엇이며, 어떻게 해결하나요? ⭐⭐⭐

<details>
<summary>답변 보기</summary>

### 핵심 답변
경쟁 상태는 두 개 이상의 스레드가 공유 자원에 동시에 접근하여 데이터의 정합성이 깨지는 현상입니다.

### 해결 방법

| 방법 | 특징 |
|------|------|
| synchronized | 간단, 암묵적 락, 블로킹 |
| ReentrantLock | 명시적, tryLock/타임아웃 가능 |
| Atomic 클래스 | Lock-free, CAS 연산 |
| volatile | 가시성 보장 (원자성 X) |

### 상세 설명
```java
// 문제 상황
count++; // 원자적이지 않음 (read → modify → write)

// 해결 1: synchronized
public synchronized void increment() { count++; }

// 해결 2: Atomic
AtomicInteger count = new AtomicInteger();
count.incrementAndGet();
```

### 면접관이 주목하는 포인트
- 원자성(Atomicity) 개념 이해
- CAS(Compare-And-Swap) 연산 설명
- 실무 적용 경험

### 꼬리 질문 대비
- "CAS 연산이 무엇인가요?"
  → 현재 값을 예상 값과 비교 후 일치하면 새 값으로 교체하는 원자적 연산
- "synchronized와 ReentrantLock의 차이점은?"
  → ReentrantLock은 타임아웃, 인터럽트 가능, 공정성 설정 등 더 세밀한 제어 가능

### 관련 개념
- [교착 상태와 경쟁 상태](./04-deadlock-race-condition.md)

</details>

---

## Q5. Stack과 Heap 메모리의 차이점은 무엇인가요? ⭐⭐⭐

<details>
<summary>답변 보기</summary>

### 핵심 답변
Stack은 함수 호출과 지역 변수를 저장하는 영역으로 컴파일 타임에 크기가 결정되고 자동 관리됩니다. Heap은 동적으로 할당되는 객체를 저장하는 영역으로 런타임에 할당되고 GC 또는 수동으로 관리됩니다.

### 비교 표

| 구분 | Stack | Heap |
|------|-------|------|
| 할당 시점 | 컴파일 타임 | 런타임 |
| 크기 | 제한적 (~1MB) | 상대적으로 큼 |
| 속도 | 빠름 | 느림 |
| 관리 | 자동 | GC 또는 수동 |
| 스레드 공유 | 독립적 | 공유 |
| 에러 | StackOverflowError | OutOfMemoryError |

### 면접관이 주목하는 포인트
- 각 영역에 저장되는 데이터 유형
- 메모리 에러 종류와 원인
- GC와의 연관성

### 꼬리 질문 대비
- "StackOverflowError는 언제 발생하나요?"
  → 재귀 호출이 너무 깊거나, 지역 변수가 너무 많을 때
- "OutOfMemoryError 발생 시 어떻게 디버깅하나요?"
  → 힙 덤프 분석 도구(MAT, VisualVM) 사용

### 관련 개념
- [메모리 관리](./02-memory-management.md)

</details>

---

## Q6. 가상 메모리란 무엇이며 왜 필요한가요? ⭐⭐

<details>
<summary>답변 보기</summary>

### 핵심 답변
가상 메모리는 물리적 메모리 크기와 관계없이 프로세스에게 큰 주소 공간을 제공하는 기술입니다. 디스크를 메모리의 확장으로 사용하여 물리 메모리보다 큰 프로그램도 실행할 수 있게 합니다.

### 필요성
1. 물리 메모리보다 큰 프로그램 실행
2. 프로세스 간 메모리 격리 및 보호
3. 메모리 단편화 해결

### 핵심 개념
- **페이지**: 가상 메모리의 고정 크기 단위 (보통 4KB)
- **프레임**: 물리 메모리의 고정 크기 단위
- **페이지 테이블**: 가상 주소 → 물리 주소 매핑
- **TLB**: 주소 변환 캐시

### 면접관이 주목하는 포인트
- 페이지 폴트 처리 과정
- TLB의 역할과 컨텍스트 스위칭과의 관계
- 스래싱(Thrashing) 개념

### 꼬리 질문 대비
- "페이지 폴트가 발생하면 어떤 일이 일어나나요?"
  → 인터럽트 발생 → 디스크에서 페이지 로드 → 페이지 테이블 업데이트 → 재실행
- "스래싱이란 무엇인가요?"
  → 페이지 폴트가 과도하게 발생하여 CPU가 실제 작업보다 페이지 교체에 더 많은 시간을 소비하는 현상

### 관련 개념
- [가상 메모리](./05-virtual-memory.md)

</details>

---

## Q7. 뮤텍스(Mutex)와 세마포어(Semaphore)의 차이점은 무엇인가요? ⭐⭐

<details>
<summary>답변 보기</summary>

### 핵심 답변
뮤텍스는 **1개의 스레드만** 임계 영역에 접근할 수 있게 하는 동기화 도구이고, 세마포어는 **지정된 개수의 스레드**가 동시에 접근할 수 있게 하는 동기화 도구입니다.

### 비교

| 구분 | Mutex | Semaphore |
|------|-------|-----------|
| 동시 접근 | 1개 | N개 (count 지정) |
| 소유권 | 있음 (락 건 스레드만 해제) | 없음 |
| 사용 사례 | 상호 배제 | 리소스 풀 제한 |

### 예시
```java
// Semaphore 예시 (커넥션 풀)
Semaphore semaphore = new Semaphore(10); // 최대 10개

semaphore.acquire(); // 리소스 획득
try {
    // 커넥션 사용
} finally {
    semaphore.release(); // 리소스 반환
}
```

### 면접관이 주목하는 포인트
- 이진 세마포어와 뮤텍스의 차이
- 실무 적용 사례 (커넥션 풀, 스레드 풀)

### 꼬리 질문 대비
- "이진 세마포어와 뮤텍스의 차이점은?"
  → 뮤텍스는 소유권 개념이 있어 락을 건 스레드만 해제 가능, 이진 세마포어는 소유권 없음

</details>

---

## Q8. 페이지 교체 알고리즘 중 LRU에 대해 설명해주세요. ⭐

<details>
<summary>답변 보기</summary>

### 핵심 답변
LRU(Least Recently Used)는 가장 오래 사용되지 않은 페이지를 교체하는 알고리즘입니다. 최근에 사용된 페이지는 가까운 미래에도 사용될 가능성이 높다는 지역성 원리에 기반합니다.

### 페이지 교체 알고리즘 비교

| 알고리즘 | 설명 | 장점 | 단점 |
|---------|------|------|------|
| FIFO | 먼저 들어온 페이지 교체 | 구현 간단 | Belady's Anomaly |
| LRU | 가장 오래 미사용된 페이지 교체 | 성능 좋음 | 구현 복잡 |
| LFU | 사용 빈도 낮은 페이지 교체 | 빈도 고려 | 최근성 무시 |

### 면접관이 주목하는 포인트
- LRU 구현 방법 (연결 리스트 + 해시맵)
- 시간 복잡도: O(1)

### 꼬리 질문 대비
- "LRU를 어떻게 구현하나요?"
  → HashMap + Doubly Linked List 조합으로 O(1) 구현

</details>

---

## 추가 질문 (심화)

### Q9. 인터럽트(Interrupt)란 무엇인가요?
### Q10. 시스템 콜(System Call)이란 무엇인가요?
### Q11. 사용자 모드와 커널 모드의 차이는?
### Q12. 프로세스의 5가지 상태를 설명해주세요.

---

## 학습 체크리스트

- [ ] 프로세스 vs 스레드 차이 설명 가능
- [ ] 컨텍스트 스위칭 비용 설명 가능
- [ ] 데드락 4가지 조건 암기
- [ ] 경쟁 상태 해결 방법 3가지 이상 알기
- [ ] Stack vs Heap 차이 설명 가능
- [ ] 가상 메모리 필요성 설명 가능
